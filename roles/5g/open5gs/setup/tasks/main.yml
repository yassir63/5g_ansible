---
- name: RESTART_OPEN5GS_SETUP
  ansible.builtin.meta: noop

- name: Reload and restart kubelet
  ansible.builtin.shell: |
    systemctl daemon-reload
    systemctl restart kubelet
  become: true
  changed_when: false

- name: Restart CoreDNS pods after kubelet restart
  ansible.builtin.shell: |
    kubectl -n kube-system delete pod -l k8s-app=kube-dns --ignore-not-found
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  changed_when: false

- name: Wait for CoreDNS to be Ready
  ansible.builtin.shell: |
    kubectl wait -n kube-system --for=condition=Ready pod -l k8s-app=kube-dns --timeout=180s
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: wait_coredns
  retries: 3
  delay: 10
  until: wait_coredns.rc == 0
  changed_when: false

# --- Test DNS ---
- name: Test CoreDNS resolution from core node
  become: true
  delegate_to: "{{ groups['core_node'][0] }}"
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  ansible.builtin.shell: |
    set -eux
    for NODE in {{ groups['core_node'][0] }}; do
      echo "=== Testing DNS on $NODE ==="
      kubectl run dns-test-$NODE \
        --image=busybox:1.36 \
        --restart=Never \
        --overrides='{"spec": {"nodeName": "'"${NODE}"'"}}' \
        --command -- sh -c 'nslookup kubernetes.default.svc.cluster.local' || true
    done

    echo "Cleaning up test pods..."
    kubectl delete pod dns-test-{{ groups['core_node'][0] }} --ignore-not-found
  changed_when: false

- name: Label {{ groups['core_node'][0] }} for Open5GS Core scheduling
  command: kubectl label node {{ groups['core_node'][0] }} open5gs-core-node=true --overwrite
  changed_when: false

# === KYVERNO INSTALLATION START =====================================================

- name: Add and update Kyverno Helm repo
  ansible.builtin.shell: |
    helm repo add kyverno https://kyverno.github.io/kyverno/ || true
    helm repo update
  args:
    executable: /bin/bash

- name: Ensure Kyverno namespace exists
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: Namespace
      metadata:
        name: kyverno

# --- Optional cleanup if Kyverno partially installed ---
- name: Uninstall previous Kyverno (safe cleanup)
  ansible.builtin.shell: |
    helm uninstall kyverno -n kyverno || true
    kubectl delete crds -l app.kubernetes.io/name=kyverno --ignore-not-found=true
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  ignore_errors: true

# --- Flannel CNI Check ---
- name: Wait for Flannel pods to be Ready
  ansible.builtin.shell: |
    kubectl wait -n kube-flannel --for=condition=Ready pod -l app=flannel --timeout=180s
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: wait_flannel
  retries: 5
  delay: 10
  until: wait_flannel.rc == 0
  changed_when: false

- name: Wait for Flannel CNI interface (cni0) to exist on core node
  ansible.builtin.shell: |
    set -e
    echo "Checking if cni0 exists on {{ item }}..."
    for i in {1..30}; do
      if ip link show cni0 2>/dev/null; then
        echo "‚úÖ cni0 exists on {{ item }}"
        exit 0
      fi
      echo "‚è≥ Waiting for cni0 to appear on {{ item }}..."
      sleep 5
    done
    echo "‚ùå cni0 not found on {{ item }}" >&2
    exit 1
  delegate_to: "{{ item }}"
  loop: "{{ groups['core_node'] }}"
  retries: 3
  delay: 5
  register: wait_cni
  changed_when: false

# Ensure cluster networking and api endpoints are ready before Kyverno install
- name: Wait for all kube-proxy pods to be Ready
  ansible.builtin.shell: |
    set -e
    for i in $(seq 1 30); do
      not_ready=$(kubectl -n kube-system get pods -l k8s-app=kube-proxy -o jsonpath='{range .items[*]}{.metadata.name}:{range .status.containerStatuses[*]}{.ready};{end}{"\n"}{end}' | grep -c false || true)
      if [ "$not_ready" -eq 0 ]; then
        echo "‚úÖ All kube-proxy pods are ready"
        exit 0
      fi
      echo "‚è≥ Waiting for kube-proxy pods ($i/30)..."
      sleep 5
    done
    echo "‚ùå kube-proxy pods not ready after 30 retries"
    kubectl -n kube-system get pods -o wide
    exit 1
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  changed_when: false



- name: Wait for kubernetes service endpoint to exist (10.96.0.1)
  ansible.builtin.shell: |
    set -eu
    tries=0
    until kubectl -n default get endpoints kubernetes -o jsonpath='{.subsets}' | grep -q '.'; do
      tries=$((tries+1))
      if [ $tries -gt 30 ]; then
        echo "no endpoints for kubernetes service after timeout" >&2
        exit 1
      fi
      sleep 2
    done
    kubectl -n default get endpoints kubernetes -o wide
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  args:
    executable: /bin/bash
  changed_when: false
  register: kubernetes_endpoints

- name: Verify core node has a route to service IP 10.96.0.1
  ansible.builtin.shell: |
    if ip route get 10.96.0.1 >/dev/null 2>&1; then
      ip route get 10.96.0.1
      exit 0
    else
      echo "no route to 10.96.0.1 on $(hostname)" >&2
      exit 2
    fi
  delegate_to: "{{ item }}"
  loop: "{{ groups['core_node'] }}"
  register: route_check
  failed_when: false
  changed_when: false

- name: Debug route check failures if any node lacks route to 10.96.0.1
  ansible.builtin.debug:
    msg: "Node {{ item.item }}: rc={{ item.rc }} stdout='{{ item.stdout }}' stderr='{{ item.stderr }}'"
  loop: "{{ route_check.results }}"
  when: item.rc != 0

- name: Check if no route to 10.96.0.1 on core node 
  ansible.builtin.fail:
    msg: "Core node does not have a route to 10.96.0.1; Kyverno install deferred."
  when: route_check.results | selectattr('rc','ne',0) | list | length > 0

# --- Install CRDs first (fixes the init crash) ---
- name: Download Kyverno chart locally
  ansible.builtin.shell: |
    rm -rf /tmp/kyverno
    mkdir -p /tmp/kyverno
    helm pull kyverno/kyverno --version 3.5.2 --untar --untardir /tmp/kyverno
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

- name: Find actual untarred Kyverno folder
  ansible.builtin.find:
    paths: /tmp/kyverno
    file_type: directory
    patterns: "kyverno*"
  register: kyverno_chart_folder

- name: Fail if no Kyverno chart folder found
  ansible.builtin.fail:
    msg: "No Kyverno chart folder found in /tmp/kyverno. Helm pull may have failed."
  when: kyverno_chart_folder.matched == 0

- name: Install Kyverno CRDs (if present) before helm install
  ansible.builtin.shell: |
    set -e
    chart_dir="{{ kyverno_chart_folder.files[0].path }}"
    if [ -d "$chart_dir/crds" ]; then
      kubectl apply -f "$chart_dir/crds"
    else
      echo "No crds directory in $chart_dir, skipping CRD apply"
    fi
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

- name: Install Kyverno Helm chart (Helm manages CRDs)
  ansible.builtin.shell: |
    helm upgrade --install kyverno {{ kyverno_chart_folder.files[0].path }} \
      -n kyverno --create-namespace --wait=false
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

# --- Wait for Kyverno controllers to be ready ---
- name: Wait for Kyverno controller pods to be Ready
  ansible.builtin.shell: |
    set -e
    kubectl -n kyverno wait --for=condition=Available deployment/kyverno-admission-controller --timeout=180s
    kubectl -n kyverno wait --for=condition=Available deployment/kyverno-background-controller --timeout=180s
    kubectl -n kyverno wait --for=condition=Available deployment/kyverno-cleanup-controller --timeout=180s
    kubectl -n kyverno wait --for=condition=Available deployment/kyverno-reports-controller --timeout=180s
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: wait_kyverno
  retries: 5
  delay: 15
  until: wait_kyverno.rc == 0
  changed_when: false

# --- Status summary (replacement for debug block) ---
- name: Show Kyverno status summary
  ansible.builtin.shell: |
    echo "üîπ Kyverno Deployments:"
    kubectl -n kyverno get deploy -o wide
    echo -e "\nüîπ Kyverno Pods:"
    kubectl -n kyverno get pods -o wide
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  changed_when: false

- name: Copy Kyverno policy to force Open5GS pods to {{ groups['core_node'][0] }}
  copy:
    dest: /tmp/force-open5gs-node.yaml
    content: |
      apiVersion: kyverno.io/v1
      kind: ClusterPolicy
      metadata:
        name: force-open5gs-to-core-node
      spec:
        rules:
          - name: add-open5gs-node-selector
            match:
              resources:
                kinds: ["Pod"]
                selector:
                  matchLabels:
                    app: open5gs
            mutate:
              patchStrategicMerge:
                spec:
                  nodeSelector:
                    open5gs-core-node: "true"

- name: Apply Kyverno policy
  command: kubectl apply -f /tmp/force-open5gs-node.yaml
  changed_when: false


# === KYVERNO INSTALLATION END =====================================================

- name: Clone open5gs-k8s repo
  ansible.builtin.git:
    repo: "{{ repo_url }}"
    dest: "{{ repo_dest }}"
    version: main
    update: yes
    force: yes

- name: Set subscriber variables
  set_fact:
    mongo_namespace: "open5gs"
    mongo_pod: "mongodb-0"
    mongo_local_port: 27017
    yaml_file: "{{ playbook_dir }}/../group_vars/all/5g_profile_{{ fiveg_profile | default('default') }}.yaml"
    mongo_tools_dir: "/root/open5gs-k8s/mongo-tools"
    python_venv: "/root/open5gs-k8s/venv/bin/python"
    python_script: "add-subscribers.py"

- name: Ensure {{ open5gs_ns }} namespace exists
  kubernetes.core.k8s:
    api_version: v1
    kind: Namespace
    name: "{{ open5gs_ns }}"
    state: present

- name: Apply MongoDB with Kustomize
  ansible.builtin.command: kubectl apply -k "{{ repo_dest }}/mongodb" -n {{ open5gs_ns }}

- name: Wait for MongoDB pod to be Ready
  kubernetes.core.k8s_info:
    kind: Pod
    namespace: "{{ open5gs_ns }}"
    label_selectors:
      - app.kubernetes.io/name=mongodb
  register: mongo_pods
  until: >
    mongo_pods.resources | length > 0 and
    (mongo_pods.resources[0].status.containerStatuses is defined) and
    (mongo_pods.resources[0].status.containerStatuses | length > 0) and
    (mongo_pods.resources[0].status.containerStatuses[0].ready | default(false))
  retries: 40
  delay: 5

# === NETWORK ATTACHMENT DEFINITIONS (NADs) ===
- name: Apply NADs with Kustomize
  ansible.builtin.command: kubectl apply -k "{{ repo_dest }}/networks5g" -n {{ open5gs_ns }}

- name: Wait for kube-apiserver to be responsive
  shell: kubectl get --raw='/healthz'
  register: api_health
  retries: 30
  delay: 5
  until: api_health.rc == 0
  changed_when: false

- name: Wait for CRDs registration to be ready
  shell: kubectl get crds
  register: crd_list
  retries: 20
  delay: 5
  until: "'network-attachment-definitions.k8s.cni.cncf.io' in crd_list.stdout"
  changed_when: false

- name: Install jq (required for NAD patching)
  ansible.builtin.apt:
    name: jq
    state: present
    update_cache: yes
  become: yes

- name: Wait for Multus CRD to be registered
  ansible.builtin.shell: kubectl get crd network-attachment-definitions.k8s.cni.cncf.io
  register: multus_crd_check
  retries: 60
  delay: 5
  until: multus_crd_check.rc == 0
  changed_when: false
  failed_when: false

- name: Patch NADs to use unique interface names (net1/net2/net3)
  shell: |
    set -euo pipefail
    for nad in n2network n3network n4network; do
      case "$nad" in
        n2network) ifname=net1 ;;
        n3network) ifname=net2 ;;
        n4network) ifname=net3 ;;
        *) continue ;;
      esac
      if ! kubectl get networkattachmentdefinition "$nad" -n open5gs &>/dev/null; then
        echo "Skipping $nad (not yet created)"
        continue
      fi
      config=$(kubectl get networkattachmentdefinition "$nad" -n open5gs -o jsonpath='{.spec.config}')
      newconfig=$(echo "$config" | jq --arg n "$ifname" '.ifname = $n')
      kubectl patch networkattachmentdefinition "$nad" -n open5gs --type=merge -p "{\"spec\":{\"config\":$newconfig}}"
    done
  register: patch_nad
  failed_when: false
  changed_when: "'Skipping' not in patch_nad.stdout"

- name: Verify required NADs exist
  kubernetes.core.k8s_info:
    kind: NetworkAttachmentDefinition
    namespace: "{{ open5gs_ns }}"
  register: nad_info

- name: Fail if a required NAD is missing
  ansible.builtin.fail:
    msg: "NAD {{ item }} is missing in {{ open5gs_ns }}"
  when: item not in (nad_info.resources | map(attribute='metadata.name') | list)
  loop: "{{ nad_list }}"

##### Patch open5gs with new 5G parameters 

- name: Load 5G profile from YAML
  ansible.builtin.include_vars:
    file: "{{ playbook_dir }}/../group_vars/all/5g_profile_{{ fiveg_profile | default('default') }}.yaml"
    name: fiveg_profile_data

- name: Validate 5G profile
  import_tasks: "../../fiveg_profile/tasks/validate.yml"
  vars:
    plmn: "{{ fiveg_profile_data.plmn }}"
    slices: "{{ fiveg_profile_data.slices }}"
    ues: "{{ fiveg_profile_data.ues }}"

- name: Generate Open5GS ConfigMap YAML
  ansible.builtin.template:
    src: open5gs-configmap.yaml.j2
    dest: /tmp/open5gs-configmap.yaml
  vars:
    fiveg_profile_data: "{{ fiveg_profile_data }}"

- name: Apply Open5GS ConfigMap
  kubernetes.core.k8s:
    state: present
    src: /tmp/open5gs-configmap.yaml
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

#####

- name: Apply Open5GS NFs with Kustomize
  ansible.builtin.command: kubectl apply -k "{{ repo_dest }}/{{ deployment_option }}" -n {{ open5gs_ns }}

- name: Wait for Open5GS Core NFs pods Ready
  kubernetes.core.k8s_info:
    kind: Pod
    namespace: "{{ open5gs_ns }}"
    label_selectors:
      - "nf={{ item }}"
  register: nf_pod
  until: >
    nf_pod.resources | length > 0 and
    (nf_pod.resources[0].status.containerStatuses is defined) and
    (nf_pod.resources[0].status.containerStatuses | length > 0) and
    (nf_pod.resources[0].status.containerStatuses[0].ready | default(false))
  retries: 40
  delay: 5
  loop: "{{ nfs }}"
  loop_control:
    label: "{{ item }}"
- name: Install python3-venv (required for venv)
  ansible.builtin.apt:
    name: python3-venv
    state: present
  become: yes

- name: Create Python virtual environment for Open5GS admin scripts
  ansible.builtin.command:
    cmd: python3 -m venv "{{ repo_dest }}/venv"
    creates: "{{ repo_dest }}/venv/bin/activate"
  become: yes

- name: Upgrade pip in virtualenv
  ansible.builtin.pip:
    name: pip
    state: latest
    executable: "{{ repo_dest }}/venv/bin/pip"
  become: yes

- name: Install Python requirements for admin script
  ansible.builtin.pip:
    requirements: "{{ repo_dest }}/requirements.txt"
    executable: "{{ repo_dest }}/venv/bin/pip"
  become: yes

- name: Deploy Open5GS Web UI with Kustomize
  ansible.builtin.command: kubectl apply -k "{{ repo_dest }}/open5gs-webui" -n {{ open5gs_ns }}

- name: Wait for WebUI pod Ready
  kubernetes.core.k8s_info:
    kind: Pod
    namespace: "{{ open5gs_ns }}"
    label_selectors:
      - "nf=webui"
  register: webui_pod
  until: >
    webui_pod.resources | length > 0 and
    (webui_pod.resources[0].status.containerStatuses is defined) and
    (webui_pod.resources[0].status.containerStatuses | length > 0) and
    (webui_pod.resources[0].status.containerStatuses[0].ready | default(false))
  retries: 40
  delay: 5

- name: Run add-admin-account.py
  ansible.builtin.command: >
    {{ repo_dest }}/venv/bin/python mongo-tools/add-admin-account.py
  args:
    chdir: "{{ repo_dest }}"

# --- Ensure lsof is installed ---
- name: Ensure lsof is installed
  ansible.builtin.apt:
    name: lsof
    state: present
    update_cache: yes
  become: yes

# --- Check if port 27017 is already used by kubectl ---
- name: Check for existing MongoDB port-forward
  ansible.builtin.shell: |
    lsof -iTCP:{{ mongo_local_port }} -sTCP:LISTEN -Fn | grep -q 'kubectl' && echo "exists" || echo ""
  register: port_forward_check
  changed_when: false

# --- Start port-forward only if not existing ---
- name: Start MongoDB port-forward if not already running
  ansible.builtin.shell: |
    nohup kubectl port-forward -n {{ mongo_namespace }} {{ mongo_pod }} {{ mongo_local_port }}:27017 > /tmp/port-forward.log 2>&1 &
    echo $! > /tmp/port-forward.pid
  when: port_forward_check.stdout == ""
  async: 0
  poll: 0

# --- Wait until MongoDB is responsive ---
- name: Wait until MongoDB accepts connections
  ansible.builtin.wait_for:
    host: 127.0.0.1
    port: "{{ mongo_local_port }}"
    delay: 2
    timeout: 180

# --- Add subscribers ---
- name: Add subscribers
  ansible.builtin.shell: |
    {{ repo_dest }}/venv/bin/python mongo-tools/generate-data.py && \
    {{ repo_dest }}/venv/bin/python mongo-tools/add-subscribers.py
  args:
    chdir: "{{ repo_dest }}"
  register: sub_out
  changed_when: false

- name: Check added subscribers
  ansible.builtin.shell: |
    {{ repo_dest }}/venv/bin/python mongo-tools/check-subscribers.py
  args:
    chdir: "{{ repo_dest }}"
  register: check_out
  changed_when: false

- name: Show added subscribers
  debug:
    var: check_out.stdout

# --- Optional block: Verify applied 5G slices in Open5GS (SMF) ---
- name: Optional block to verify applied 5G slices in Open5GS
  block:

    - name: Load 5G scenario profile
      ansible.builtin.include_vars:
        file: "{{ playbook_dir }}/../group_vars/all/5g_profile_{{ fiveg_profile | default('default') }}.yaml"
        name: fiveg

    - name: Get SMF pod
      kubernetes.core.k8s_info:
        kind: Pod
        namespace: "{{ open5gs_ns }}"
        label_selectors:
          - "nf=smf"
      register: smf_pods

    - name: Select first SMF pod
      set_fact:
        smf_pod: "{{ smf_pods.resources[0].metadata.name }}"

    - name: Read SMF configuration
      kubernetes.core.k8s_exec:
        namespace: "{{ open5gs_ns }}"
        pod: "{{ smf_pod }}"
        command: cat /open5gs/install/etc/open5gs/smf.yaml
      register: smf_raw

    - name: Parse SMF YAML
      set_fact:
        smf_cfg: "{{ smf_raw.stdout | from_yaml }}"

    - name: Display slice verification (GREEN / RED)
      debug:
        msg: |
          {% for exp in fiveg.slices %}
          {% set match = (
               smf_cfg.smf.slice
               | selectattr('sst', 'equalto', exp.sst | int)
               | selectattr('sd', 'equalto', (exp.sd if exp.sd != 'EMPTY' else omit))
               | selectattr('dnn', 'equalto', exp.dnn)
               | list
          ) %}
          {% if match | length > 0 %}
          ‚úÖ SLICE OK
          {% else %}
          ‚ùå SLICE KO
          {% endif %}
          slice:
            name: {{ exp.name }}
            sst: {{ exp.sst }}
            sd: {{ exp.sd }}
            dnn: {{ exp.dnn }}
            qos:
              five_qi: {{ exp.qos.five_qi }}
              priority_level: {{ exp.qos.priority_level }}

          {% endfor %}

  when: mtnt_show_open5gs_config | default(false)
