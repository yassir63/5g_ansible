---
- name: Label {{ groups['core_node'][0] }} for Open5GS Core scheduling
  command: kubectl label node {{ groups['core_node'][0] }} open5gs-core-node=true --overwrite
  changed_when: false

- name: Add Kyverno Helm repo
  ansible.builtin.shell: |
    helm repo add kyverno https://kyverno.github.io/kyverno/
    helm repo update
  args:
    executable: /bin/bash

- name: Remove old Kyverno chart folder if it exists
  ansible.builtin.file:
    path: /tmp/kyverno
    state: absent

- name: Ensure /tmp/kyverno exists
  ansible.builtin.file:
    path: /tmp/kyverno
    state: directory

- name: Backup and remove existing Kyverno CRDs if present
  block:
    - name: Find existing Kyverno CRDs
      kubernetes.core.k8s_info:
        api_version: apiextensions.k8s.io/v1
        kind: CustomResourceDefinition
      register: kyverno_crds
    - name: Backup CRDs
      copy:
        content: "{{ item | to_nice_yaml }}"
        dest: "~/kyverno-crd-backup-{{ item.metadata.name }}.yaml"
      loop: "{{ kyverno_crds.resources }}"
      when: "'kyverno.io' in item.metadata.name"
    - name: Delete CRDs
      kubernetes.core.k8s:
        state: absent
        definition: "{{ item }}"
      loop: "{{ kyverno_crds.resources }}"
      when: "'kyverno.io' in item.metadata.name"
  ignore_errors: yes

- name: Download Kyverno chart locally
  ansible.builtin.shell: |
    helm pull kyverno/kyverno --version 2.5.3 --untar --untardir /tmp/kyverno
  args:
    executable: /bin/bash

- name: Find actual untarred Kyverno folder
  ansible.builtin.find:
    paths: /tmp/kyverno
    file_type: directory
    patterns: "kyverno*"
  register: kyverno_chart_folder

- name: Fail if no Kyverno chart folder found
  ansible.builtin.fail:
    msg: "No Kyverno chart folder found in /tmp/kyverno. Helm pull may have failed."
  when: kyverno_chart_folder.matched == 0

- name: Get CoreDNS service IP
  kubernetes.core.k8s_info:
    kind: Service
    name: kube-dns
    namespace: kube-system
  register: coredns
  retries: 5
  delay: 5
  until: coredns.resources | length > 0

- name: Set CoreDNS IP fact
  set_fact:
    coredns_ip: "{{ coredns.resources[0].spec.clusterIP }}"

- name: Install Kyverno (clean reinstall, tolerant)
  ansible.builtin.shell: |
    set -euo pipefail
    echo "[INFO] Installing Kyverno Helm chart (tolerant mode)..."
    helm upgrade --install kyverno kyverno/kyverno \
      --namespace kyverno --create-namespace --version 2.5.3 \
      --timeout 15m0s --atomic=false \
      --set kyvernoPre.enabled=false \
      --set admissionController.podSpec.hostNetwork=true \
      --set admissionController.podSpec.dnsPolicy=ClusterFirstWithHostNet || true
    echo "[WARN] Helm install may have partially succeeded, will verify pods manually."
  args:
    executable: /bin/bash
  register: kyverno_install
  changed_when: true
  failed_when: false
    
- name: Wait for Kyverno deployment to be ready
  kubernetes.core.k8s_info:
    api_version: apps/v1
    kind: Deployment
    namespace: kyverno
    name: kyverno
  register: kyverno_status
  until:
    - kyverno_status.resources | length > 0
    - kyverno_status.resources[0].status.readyReplicas is defined
    - kyverno_status.resources[0].status.readyReplicas >= 1
  retries: 40
  delay: 15
  ignore_errors: yes

- name: Debug Kyverno deployment and pods if not ready
  block:
    - debug:
        var: kyverno_status.resources[0].status
    - name: List Kyverno pods
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        namespace: kyverno
      register: kyverno_pods
    - debug:
        var: kyverno_pods.resources
    - name: Fetch init container logs for Kyverno pods
      ansible.builtin.shell: |
        kubectl logs -n kyverno {{ item.0.metadata.name }} -c {{ item.1.name }} --tail=50
      loop: "{{ (kyverno_pods.resources | d([])) | subelements('spec.initContainers', skip_missing=True) }}"
      loop_control:
        label: "{{ item.0.metadata.name }} / {{ item.1.name }}"
      register: init_logs
      ignore_errors: yes
    - name: Display init container logs
      debug:
        var: init_logs.results
  when: kyverno_status is failed

- name: Copy Kyverno policy to force Open5GS pods to {{ groups['core_node'][0] }}
  copy:
    dest: /tmp/force-open5gs-node.yaml
    content: |
      apiVersion: kyverno.io/v1
      kind: ClusterPolicy
      metadata:
        name: force-open5gs-to-core-node
      spec:
        mutateExistingOnPolicyUpdate: true
        rules:
          - name: add-open5gs-node-selector
            match:
              resources:
                kinds: ["Pod"]
                selector:
                  matchLabels:
                    app: open5gs
            mutate:
              patchStrategicMerge:
                spec:
                  nodeSelector:
                    open5gs-core-node: "true"

- name: Apply Kyverno policy
  command: kubectl apply -f /tmp/force-open5gs-node.yaml
  changed_when: false

- name: Clone open5gs-k8s repo
  ansible.builtin.git:
    repo: "{{ repo_url }}"
    dest: "{{ repo_dest }}"
    version: main
    update: yes
    force: yes

- name: Ensure {{ open5gs_ns }} namespace exists
  kubernetes.core.k8s:
    api_version: v1
    kind: Namespace
    name: "{{ open5gs_ns }}"
    state: present

- name: Apply MongoDB with Kustomize
  ansible.builtin.command: kubectl apply -k "{{ repo_dest }}/mongodb" -n {{ open5gs_ns }}

- name: Wait for MongoDB pod to be Ready
  kubernetes.core.k8s_info:
    kind: Pod
    namespace: "{{ open5gs_ns }}"
    label_selectors:
      - app.kubernetes.io/name=mongodb
  register: mongo_pods
  until: >
    mongo_pods.resources | length > 0 and
    (mongo_pods.resources[0].status.containerStatuses is defined) and
    (mongo_pods.resources[0].status.containerStatuses | length > 0) and
    (mongo_pods.resources[0].status.containerStatuses[0].ready | default(false))
  retries: 40
  delay: 5

# 1. Apply NADs (creates the objects)
- name: Apply NADs with Kustomize
  ansible.builtin.command: kubectl apply -k "{{ repo_dest }}/networks5g" -n {{ open5gs_ns }}

# 2. WAIT FOR MULTUS CRD
- name: Wait for kube-apiserver to be responsive
  shell: kubectl get --raw='/healthz'
  register: api_health
  retries: 30
  delay: 5
  until: api_health.rc == 0
  changed_when: false

- name: Wait for CRDs registration to be ready
  shell: kubectl get crds
  register: crd_list
  retries: 20
  delay: 5
  until: "'network-attachment-definitions.k8s.cni.cncf.io' in crd_list.stdout"
  changed_when: false

# 3. Install jq (needed for patching)
- name: Install jq (required for NAD patching)
  ansible.builtin.apt:
    name: jq
    state: present
    update_cache: yes
  become: yes

# 4. Patch NADs to avoid interface name conflict
- name: Wait for Multus CRD to be registered in API server
  ansible.builtin.shell: kubectl get crd network-attachment-definitions.k8s.cni.cncf.io
  register: multus_crd_check
  retries: 60
  delay: 5
  until: multus_crd_check.rc == 0
  changed_when: false
  failed_when: false

# Ensure Multus CRD is available before proceeding
- name: Wait for Cluster Network Addons Operator to deploy Multus CRD
  ansible.builtin.shell: |
    set -e
    kubectl wait deployment -n cluster-network-addons cluster-network-addons-operator --for=condition=Available --timeout=300s || true
    until kubectl get crd network-attachment-definitions.k8s.cni.cncf.io >/dev/null 2>&1; do
      echo "â³ Waiting for Multus CRD..."
      sleep 5
    done
  register: wait_multus_crd
  changed_when: false
  failed_when: false
  
- name: Patch NADs to use unique interface names (net1/net2/net3)
  shell: |
    set -euo pipefail
    for nad in n2network n3network n4network; do
      case "$nad" in
        n2network) ifname=net1 ;;
        n3network) ifname=net2 ;;
        n4network) ifname=net3 ;;
        *) continue ;;
      esac
      if ! kubectl get networkattachmentdefinition "$nad" -n open5gs &>/dev/null; then
        echo "Skipping $nad (not yet created)"
        continue
      fi
      config=$(kubectl get networkattachmentdefinition "$nad" -n open5gs -o jsonpath='{.spec.config}')
      newconfig=$(echo "$config" | jq --arg n "$ifname" '.ifname = $n')
      kubectl patch networkattachmentdefinition "$nad" -n open5gs --type=merge -p "{\"spec\":{\"config\":$newconfig}}"
    done
  register: patch_nad
  failed_when: false
  changed_when: "'Skipping' not in patch_nad.stdout"

- name: Verify required NADs exist
  kubernetes.core.k8s_info:
    kind: NetworkAttachmentDefinition
    namespace: "{{ open5gs_ns }}"
  register: nad_info

- name: Fail if a required NAD is missing
  ansible.builtin.fail:
    msg: "NAD {{ item }} is missing in {{ open5gs_ns }}"
  when: item not in (nad_info.resources | map(attribute='metadata.name') | list)
  loop: "{{ nad_list }}"

- name: Apply Open5GS NFs with Kustomize
  ansible.builtin.command: kubectl apply -k "{{ repo_dest }}/{{ deployment_option }}" -n {{ open5gs_ns }}

- name: Wait for Open5GS Core NFs pods Ready
  kubernetes.core.k8s_info:
    kind: Pod
    namespace: "{{ open5gs_ns }}"
    label_selectors:
      - "nf={{ item }}"
  register: nf_pod
  until: >
    nf_pod.resources | length > 0 and
    (nf_pod.resources[0].status.containerStatuses is defined) and
    (nf_pod.resources[0].status.containerStatuses | length > 0) and
    (nf_pod.resources[0].status.containerStatuses[0].ready | default(false))
  retries: 40
  delay: 5
  loop: "{{ nfs }}"
  loop_control:
    label: "{{ item }}"

- name: Install python3-venv (required for venv)
  ansible.builtin.apt:
    name: python3-venv
    state: present
  become: yes

- name: Create Python virtual environment for Open5GS admin scripts
  ansible.builtin.command:
    cmd: python3 -m venv "{{ repo_dest }}/venv"
    creates: "{{ repo_dest }}/venv/bin/activate"
  become: yes

- name: Upgrade pip in virtualenv
  ansible.builtin.pip:
    name: pip
    state: latest
    executable: "{{ repo_dest }}/venv/bin/pip"
  become: yes

- name: Install Python requirements for admin script
  ansible.builtin.pip:
    requirements: "{{ repo_dest }}/requirements.txt"
    executable: "{{ repo_dest }}/venv/bin/pip"
  become: yes

- name: Deploy Open5GS Web UI with Kustomize
  ansible.builtin.command: kubectl apply -k "{{ repo_dest }}//open5gs-webui" -n {{ open5gs_ns }}

- name: Wait for WebUI pod Ready
  kubernetes.core.k8s_info:
    kind: Pod
    namespace: "{{ open5gs_ns }}"
    label_selectors:
      - "nf=webui"
  register: webui_pod
  until: >
    webui_pod.resources | length > 0 and
    (webui_pod.resources[0].status.containerStatuses is defined) and
    (webui_pod.resources[0].status.containerStatuses | length > 0) and
    (webui_pod.resources[0].status.containerStatuses[0].ready | default(false))
  retries: 40
  delay: 5

- name: Run add-admin-account.py
  ansible.builtin.command: >
    {{ repo_dest }}/venv/bin/python mongo-tools/add-admin-account.py
  args:
    chdir: "{{ repo_dest }}"

- name: Add subscribers
  ansible.builtin.shell: |
    {{ repo_dest }}/venv/bin/python mongo-tools/generate-data.py && \
    {{ repo_dest }}/venv/bin/python mongo-tools/add-subscribers.py
  args:
    chdir: "{{ repo_dest }}"
  register: sub_out
  changed_when: false

- name: Check added subscribers
  ansible.builtin.shell: |
    {{ repo_dest }}/venv/bin/python mongo-tools/check-subscribers.py
  args:
    chdir: "{{ repo_dest }}"
  register: check_out
  changed_when: false

- name: Show Added subscribers
  debug:
    var: check_out.stdout
    