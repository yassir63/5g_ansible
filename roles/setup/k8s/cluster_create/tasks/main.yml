# =============================
# Kubernetes Cluster Initialization
# =============================

- name: Detect if RT (Benetel) setup is required
  set_fact:
    is_rt: "{{ hostvars[groups['faraday'][0]].rru in ['benetel1', 'benetel2'] }}"

# --- Safety cleanup (if previous kubeadm init failed)
- name: Reset Kubernetes if a previous init was attempted
  command: kubeadm reset -f
  ignore_errors: yes
  become: true

- name: Remove old Kubernetes data directories
  file:
    path: "{{ item }}"
    state: absent
  loop:
    - /etc/kubernetes/pki
    - /etc/kubernetes/manifests
    - /var/lib/etcd
    - /var/lib/kubelet
  become: true

- name: Upload kubeadm config to master node
  copy:
    src: "{{ 'kubeadm-config-rt.yaml' if is_rt else 'kubeadm-config.yaml' }}"
    dest: /root/kubeadm-config.yaml
    mode: '0644'
  become: true

# --- Initialize Kubernetes cluster
- name: Initialize Kubernetes cluster with kubeadm config
  command: kubeadm init --config /root/kubeadm-config.yaml
  register: kubeadm_init
  failed_when: kubeadm_init.rc != 0
  changed_when: kubeadm_init.rc == 0
  become: true

# --- Verify RT-specific kubelet CPU isolation
- name: Verify reservedSystemCPUs in kubelet config
  command: grep 'reservedSystemCPUs' /var/lib/kubelet/config.yaml
  register: kubelet_reserved
  failed_when: "'0-5' not in kubelet_reserved.stdout"
  changed_when: false
  when: is_rt
  become: true

- name: Show verification result
  debug:
    msg: "âœ… reservedSystemCPUs is correctly set to 0-5 in kubelet config"
  when: is_rt

# --- Configure kubectl access for current user
- name: Create .kube directory
  file:
    path: "{{ ansible_env.HOME }}/.kube"
    state: directory
    mode: '0700'

- name: Copy admin.conf to kube config
  copy:
    src: /etc/kubernetes/admin.conf
    dest: "{{ ansible_env.HOME }}/.kube/config"
    remote_src: yes
    mode: '0600'
  become: true

# --- Apply sysctl for RT nodes safely
- name: Apply RT sysctl settings
  shell: sysctl -p /etc/sysctl.d/rt.conf || true
  become: true
  when: is_rt

# --- Install Flannel (CNI) before CoreDNS
- name: Ensure dependencies for Helm/Flannel
  apt:
    name:
      - python3-pip
      - curl
    state: present
    update_cache: yes
  become: true

- name: Install Kubernetes Python client
  pip:
    name: kubernetes
    executable: pip3
  become: true

- name: Download Helm install script
  get_url:
    url: https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
    dest: /tmp/get-helm-3
    mode: '0755'
  become: true

- name: Install Helm (if not already)
  command: /tmp/get-helm-3
  args:
    creates: /usr/local/bin/helm
  become: true

- name: Create kube-flannel namespace with pod-security label
  kubernetes.core.k8s:
    definition:
      apiVersion: v1
      kind: Namespace
      metadata:
        name: kube-flannel
        labels:
          pod-security.kubernetes.io/enforce: privileged
    state: present
    apply: yes
  become: true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

- name: Add Flannel Helm repo
  kubernetes.core.helm_repository:
    name: flannel
    repo_url: https://flannel-io.github.io/flannel/
  become: true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

- name: Install Flannel via Helm
  kubernetes.core.helm:
    name: flannel
    chart_ref: flannel/flannel
    release_namespace: kube-flannel
    create_namespace: false
    state: present
    wait: true
    wait_timeout: 300s
  become: true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

# --- Install Multus after CoreDNS is ready
- name: Upload Multus DaemonSet manifest
  copy:
    src: multus-daemonset.yml
    dest: /root/multus-daemonset.yml
    mode: '0644'
  become: true

- name: Apply Multus DaemonSet
  kubernetes.core.k8s:
    state: present
    src: /root/multus-daemonset.yml
  become: true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

- name: Wait for Multus DaemonSet to be ready
  kubernetes.core.k8s_info:
    api_version: apps/v1
    kind: DaemonSet
    namespace: kube-system
    name: kube-multus-ds
  register: multus_ds_info
  until:
    - multus_ds_info.resources | length > 0
    - multus_ds_info.resources[0].status.desiredNumberScheduled | default(0) > 0
    - multus_ds_info.resources[0].status.numberReady | default(0) ==
      multus_ds_info.resources[0].status.desiredNumberScheduled
  retries: 40
  delay: 15
  become: true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

# --- Wait for CoreDNS pods to be ready
- name: Wait for CoreDNS pods to be Ready
  shell: kubectl wait -n kube-system --for=condition=Ready pod -l k8s-app=kube-dns --timeout=300s
  register: coredns_wait
  retries: 5
  delay: 10
  until: coredns_wait.rc == 0
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  become: true


# --- Remove master taint to allow scheduling
- name: Remove NoSchedule taint from control-plane node
  command: kubectl taint nodes --all node-role.kubernetes.io/control-plane:NoSchedule-
  failed_when: false
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  become: true

# --- Generate kubeadm join command for workers
- name: Generate kubeadm join command
  shell: kubeadm token create --print-join-command
  register: join_command
  run_once: true
  delegate_to: "{{ groups['core_node'][0] }}"
  become: true

# --- Create custom join configuration for RT setup
- name: Create custom join configuration for RT setup
  copy:
    dest: /tmp/join-config.yaml
    content: |
      apiVersion: kubeadm.k8s.io/v1beta3
      kind: JoinConfiguration
      nodeRegistration:
        kubeletExtraArgs:
          cgroup-driver: systemd
          cpu-manager-policy: static
          cpu-manager-policy-options: "full-pcpus-only=true"
          reserved-system-cpus: 0-5
          topology-manager-policy: best-effort
          fail-swap-on: "false"
          container-log-max-size: 50Mi
          feature-gates: CPUManager=true,CPUManagerPolicyOptions=true,CPUManagerPolicyBetaOptions=true
  when: is_rt
  become: true
  run_once: true
  delegate_to: "{{ groups['core_node'][0] }}"

- name: Save final join command to file
  copy:
    dest: /tmp/kubeadm_join_command.txt
    content: |
      {% if is_rt %}
      kubeadm join --config /tmp/join-config.yaml
      {% else %}
      {{ join_command.stdout }}
      {% endif %}
    mode: '0644'
  run_once: true
  delegate_to: localhost

