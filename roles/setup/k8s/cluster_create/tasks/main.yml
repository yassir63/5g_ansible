---
- name: RESTART_K8S_CREATE
  ansible.builtin.meta: noop

# =============================================================================
# CLEANUP
# =============================================================================
- name: Reset Kubernetes
  ansible.builtin.command: kubeadm reset -f
  ignore_errors: true
  become: true

- name: Remove old data
  ansible.builtin.file:
    path: "{{ item }}"
    state: absent
  loop:
    - /etc/kubernetes
    - /var/lib/kubelet
    - /var/lib/etcd
    - /var/lib/containerd
  become: true

# =============================================================================
# CONFIGURE containerd FOR overlayfs + CRI
# =============================================================================
- name: Write containerd config with overlayfs + user mode
  ansible.builtin.copy:
    dest: /etc/containerd/config.toml
    content: |
      version = 2
      [plugins."io.containerd.grpc.v1.cri"]
        sandbox_image = "registry.k8s.io/pause:3.10"
        [plugins."io.containerd.grpc.v1.cri".containerd]
          default_runtime_name = "runc"
          snapshotter = "overlayfs"
          [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
            runtime_type = "io.containerd.runc.v2"
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
              SystemdCgroup = true
    mode: '0644'
  become: true
  when: inventory_hostname == groups['core_node'][0]

- name: Restart containerd
  ansible.builtin.systemd:
    name: containerd
    state: restarted
  become: true
  when: inventory_hostname == groups['core_node'][0]

- name: Wait for containerd
  ansible.builtin.pause:
    seconds: 15
  when: inventory_hostname == groups['core_node'][0]

# =============================================================================
# PULL IMAGES USING crictl (RESPECTS CRI + overlayfs)
# =============================================================================
- name: Pull K8s images using crictl --user 0:0 (bypass whiteout bug)
  ansible.builtin.shell: |
    crictl pull --creds="" --user 0:0 {{ item }}
  loop:
    - registry.k8s.io/kube-apiserver:v1.32.9
    - registry.k8s.io/kube-controller-manager:v1.32.9
    - registry.k8s.io/kube-scheduler:v1.32.9
    - registry.k8s.io/kube-proxy:v1.32.9
    - registry.k8s.io/etcd:3.5.15-0
    - registry.k8s.io/coredns/coredns:v1.11.1
  become: true
  when: inventory_hostname == groups['core_node'][0]
  register: crictl_pull
  retries: 5
  delay: 15
  until: crictl_pull.rc == 0
  ignore_errors: false

# =============================================================================
# UPLOAD & MIGRATE CONFIG
# =============================================================================
- name: Upload kubeadm config
  ansible.builtin.copy:
    src: kubeadm-config.yaml
    dest: /root/kubeadm-config.yaml
    mode: '0644'
  become: true

- name: Migrate kubeadm config to v1beta4
  ansible.builtin.shell: |
    kubeadm config migrate --old-config /root/kubeadm-config.yaml --new-config /root/kubeadm-config-new.yaml
    mv /root/kubeadm-config-new.yaml /root/kubeadm-config.yaml
  become: true
  when: inventory_hostname == groups['core_node'][0]

# =============================================================================
# INITIALIZE CLUSTER
# =============================================================================
- name: Initialize cluster
  ansible.builtin.command: kubeadm init --config /root/kubeadm-config.yaml --skip-phases=preflight,addon/kube-proxy
  register: kubeadm_init
  failed_when: kubeadm_init.rc != 0
  changed_when: kubeadm_init.rc == 0
  become: true
  when: inventory_hostname == groups['core_node'][0]

# =============================================================================
# SETUP KUBECONFIG
# =============================================================================
- name: Create .kube
  ansible.builtin.file:
    path: "{{ ansible_env.HOME }}/.kube"
    state: directory
    mode: '0700'
  when: inventory_hostname == groups['core_node'][0]

- name: Copy admin.conf
  ansible.builtin.copy:
    src: /etc/kubernetes/admin.conf
    dest: "{{ ansible_env.HOME }}/.kube/config"
    remote_src: yes
    mode: '0600'
  become: true
  when: inventory_hostname == groups['core_node'][0]

# =============================================================================
# INSTALL HELM + CLIENT
# =============================================================================
- name: Install python3-venv, pip, curl
  ansible.builtin.apt:
    name: [python3-venv, python3-pip, curl]
    state: present
  become: true

- name: Create venv
  ansible.builtin.command: python3 -m venv /opt/k8s-venv
  args:
    creates: /opt/k8s-venv/bin/activate
  become: true

- name: Install kubernetes client
  ansible.builtin.pip:
    name: kubernetes
    executable: /opt/k8s-venv/bin/pip
  become: true

- name: Set interpreter
  ansible.builtin.set_fact:
    ansible_python_interpreter: /opt/k8s-venv/bin/python
  when: inventory_hostname == groups['core_node'][0]

- name: Install Helm
  ansible.builtin.shell: |
    curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
  args:
    creates: /usr/local/bin/helm
  become: true

# =============================================================================
# INSTALL CNI: FLANNEL
# =============================================================================
- name: Create flannel namespace
  kubernetes.core.k8s:
    definition:
      apiVersion: v1
      kind: Namespace
      metadata:
        name: kube-flannel
        labels:
          pod-security.kubernetes.io/enforce: privileged
    state: present
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: inventory_hostname == groups['core_node'][0]

- name: Add Flannel repo
  kubernetes.core.helm_repository:
    name: flannel
    repo_url: https://flannel-io.github.io/flannel/
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: inventory_hostname == groups['core_node'][0]

- name: Install Flannel
  kubernetes.core.helm:
    name: flannel
    chart_ref: flannel/flannel
    release_namespace: kube-flannel
    state: present
    wait: true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: inventory_hostname == groups['core_node'][0]

# =============================================================================
# INSTALL MULTUS
# =============================================================================
- name: Apply Multus
  kubernetes.core.k8s:
    state: present
    src: multus-daemonset.yml
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: inventory_hostname == groups['core_node'][0]

- name: Wait for Multus
  kubernetes.core.k8s_info:
    kind: DaemonSet
    namespace: kube-system
    name: kube-multus-ds
  register: multus
  until: multus.resources[0].status.numberReady == multus.resources[0].status.desiredNumberScheduled
  retries: 30
  delay: 10
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: inventory_hostname == groups['core_node'][0]

# =============================================================================
# FINALIZE
# =============================================================================
- name: Remove taint
  ansible.builtin.command: kubectl taint nodes --all node-role.kubernetes.io/control-plane:NoSchedule-
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: inventory_hostname == groups['core_node'][0]

- name: Generate join command
  ansible.builtin.shell: kubeadm token create --print-join-command
  register: join_cmd
  delegate_to: "{{ groups['core_node'][0] }}"

- name: Save join command
  ansible.builtin.copy:
    content: "{{ join_cmd.stdout }}"
    dest: /tmp/kubeadm_join_command.txt
  delegate_to: localhost
  