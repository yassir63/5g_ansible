---
# Cleanup if the node was already part of a cluster
- name: Check if node is already part of a Kubernetes cluster
  stat:
    path: /etc/kubernetes/kubelet.conf
  register: kubelet_conf

- name: Reset node if already part of a cluster
  command: kubeadm reset -f
  when: kubelet_conf.stat.exists
  ignore_errors: true

- name: Remove Kubernetes CNI configuration
  file:
    path: /etc/cni/net.d
    state: absent
  when: kubelet_conf.stat.exists

- name: Remove kubelet data directory
  file:
    path: /var/lib/kubelet
    state: absent
  when: kubelet_conf.stat.exists

- name: Restart container runtime (containerd)
  service:
    name: containerd
    state: restarted
  when: kubelet_conf.stat.exists
  ignore_errors: true


# Base setup
- name: Ensure .kube directory exists on worker node
  file:
    path: /root/.kube
    state: directory
    mode: '0755'

- name: Fetch admin.conf from master to control machine
  fetch:
    src: /etc/kubernetes/admin.conf
    dest: ./admin.conf
    flat: yes
  delegate_to: "{{ groups['core_node'][0] }}"
  when: inventory_hostname == groups['k8s_workers'][0]

- name: Copy admin.conf from control machine to worker node
  copy:
    src: ./admin.conf
    dest: /root/.kube/config
    mode: '0644'
  become: true


# Retrieve the join command
- name: Read kubeadm join command from file
  set_fact:
    kubeadm_join_command: "{{ lookup('file', '/tmp/kubeadm_join_command.txt') }}"

- name: Debug join command
  debug:
    var: kubeadm_join_command

- name: Join the node to the cluster
  command: "{{ kubeadm_join_command }} --ignore-preflight-errors=SystemVerification --v=5"

